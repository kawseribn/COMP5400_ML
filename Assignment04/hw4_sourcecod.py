# -*- coding: utf-8 -*-
"""hw4-sourcecod.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l2Cvdm2-uTnnqWwXgjGGN0fVyN9AXN1C
"""

import cv2
from pathlib import Path
from random import choice

class FaceMatcher:
    def __init__(self, data_path):
        self.data_path = Path(data_path)
        self.faces_path = self.data_path / "faces"
        self.faces_path.mkdir(exist_ok=True)
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        self.orb = cv2.ORB_create()
        self.bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)

    def load_image(self, file_path):
        image = cv2.imread(str(file_path))
        if image is None:
            print(f"Image {file_path} not found or unable to load.")
            return None
        return image

    def detect_faces(self, image):
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)
        return [image[y:y+h, x:x+w] for (x, y, w, h) in faces]

    def save_faces(self, faces, image_number):
        face_paths = []
        for idx, face in enumerate(faces):
            face_filename = f"face{image_number}_{idx}.png"
            face_path = self.faces_path / face_filename
            cv2.imwrite(str(face_path), face)
            face_paths.append(face_path)
        return face_paths

    def find_keypoints_descriptors(self, image):
        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        keypoints, descriptors = self.orb.detectAndCompute(gray_image, None)
        return keypoints, descriptors

    def match_faces(self, descriptors_to_match, image_paths):
        best_match_path = None
        best_match_score = -1
        for path in image_paths:
            image = self.load_image(path)
            if image is not None:
                keypoints, descriptors = self.find_keypoints_descriptors(image)
                if descriptors is not None and len(descriptors) > 0:
                    matches = self.bf.match(descriptors_to_match, descriptors)
                    matches = sorted(matches, key=lambda x: x.distance)
                    match_score = len(matches)
                    if match_score > best_match_score:
                        best_match_score = match_score
                        best_match_path = path
        return best_match_path, best_match_score

# Defining root dir
data_path = "/root"
# Creating FaceMatcher object to initialize all the required methods
face_matcher = FaceMatcher(data_path)

# Detecting and saving faces from images
face_images_paths = []
for i in range(1, 11):
    image_path = face_matcher.data_path / f"image{i}.png"
    if not image_path.is_file():
        image_path = face_matcher.data_path / f"image{i}.jpg"
    image = face_matcher.load_image(image_path)
    if image is not None:
        faces = face_matcher.detect_faces(image)
        face_paths = face_matcher.save_faces(faces, i)
        face_images_paths.extend(face_paths)

# Selecting a random face and finding its descriptions
random_face_path = choice(face_images_paths)
random_face_image = face_matcher.load_image(random_face_path)
_, descriptors_to_match = face_matcher.find_keypoints_descriptors(random_face_image)

# Matching the face descriptors against all original images
original_image_paths = [str(face_matcher.data_path / f"image{i}.png") if (face_matcher.data_path / f"image{i}.png").is_file() else
                        str(face_matcher.data_path / f"image{i}.jpg") if (face_matcher.data_path / f"image{i}.jpg").is_file() else None
                        for i in range(1, 11)]
original_image_paths = [path for path in original_image_paths if path is not None]
best_match_path, best_match_score = face_matcher.match_faces(descriptors_to_match, original_image_paths)

print(random_face_path, best_match_path, best_match_score)

import numpy as np
import matplotlib.pyplot as plt
import cv2
image_path = '/content/p4.png'
image = cv2.imread(image_path)
image = cv2.resize(image, (1000,400))
image1 = image.copy()
image2 = image.copy()

gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0) #smoothing the image to remove noise
edges = cv2.Canny(blurred_image, 70, 150, apertureSize=3)
linesP = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=80, minLineLength=30, maxLineGap=10)

vertical_lines = []

if linesP is not None:
    for line in linesP:
        x1, y1, x2, y2 = line[0]

        # Calculation for the angle to filter vertical lines, if necessary
        angle = np.arctan2(y2 - y1, x2 - x1) * 180.0 / np.pi

        if -60 < abs(angle) < 100 or 300 < abs(angle) < 280:
            vertical_lines.append([x1, y1, x2, y2])
            cv2.line(image1, (x1, y1), (x2, y2), (0, 0, 255), 2)

print(f'Initial number of detected lines: {len(vertical_lines)}')

min_distance = 70

def line_length(line):
    return ((line[2] - line[0])**2 + (line[3] - line[1])**2)**0.5

vertical_lines_sorted = sorted(vertical_lines, key=lambda x: x[2])

filtered_lines = [vertical_lines_sorted[0]]

for i in range(1, len(vertical_lines_sorted)):
    current_line = vertical_lines_sorted[i]
    previous_line = filtered_lines[-1]

    distance = abs(current_line[2] - previous_line[2])
    if distance > min_distance:
        filtered_lines.append(current_line)
    else:
        # If the lines are too close, compare their lengths and keep the longer one
        if line_length(current_line) > line_length(previous_line):
            filtered_lines[-1] = current_line

print(f'Final number of detected lines after filtering: {len(filtered_lines)}')
print('TOTAL FREE PARKING SPACE: ', len(filtered_lines) - 1)

for line in filtered_lines:
  # print(line)
  x1, y1, x2, y2 = line
  cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)

for idx, line in enumerate(filtered_lines[:-1], start=1):
    next_line = filtered_lines[idx]
    mid_x = (line[0] + next_line[0]) // 2
    cv2.putText(image2, str(idx), (mid_x, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)



numbered_image_dir = '/content/parking_space_numbered.png'
cv2.imwrite(numbered_image_dir, image)


plt.figure(figsize=(12, 8))
plt.subplot(3, 2, 4)
plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
plt.title('Filtered Lines Image')
plt.subplot(3, 2, 3)
plt.imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))
plt.title('Un-Filtered Lines Image')

# Display blurred image in 2nd subplot (bottom left)
plt.subplot(3, 2, 1)
plt.imshow(cv2.cvtColor(blurred_image, cv2.COLOR_BGR2RGB))
plt.title('Blurred Image')

# Display edges in 3rd subplot (bottom right)
plt.subplot(3, 2, 2)
plt.imshow(cv2.cvtColor(edges, cv2.COLOR_BGR2RGB))
plt.title('Edges')

plt.subplot(3, 2, 5)
plt.imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))
plt.title('Free Parking Space')

# plt.subplot(3, 2, 4)
# plt.imshow(cv2.cvtColor(lines, cv2.COLOR_BGR2RGB))
# plt.title('Edges')

plt.tight_layout()  # Adjust layout to make room for titles and ensure no overlap
plt.show()